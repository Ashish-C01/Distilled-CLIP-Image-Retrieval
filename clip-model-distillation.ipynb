{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-15T01:07:43.891743Z",
     "iopub.status.busy": "2025-03-15T01:07:43.891425Z",
     "iopub.status.idle": "2025-03-15T01:08:04.600282Z",
     "shell.execute_reply": "2025-03-15T01:08:04.599344Z",
     "shell.execute_reply.started": "2025-03-15T01:07:43.891718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:08:22.610395Z",
     "iopub.status.busy": "2025-03-15T01:08:22.609759Z",
     "iopub.status.idle": "2025-03-15T01:08:34.250105Z",
     "shell.execute_reply": "2025-03-15T01:08:34.249175Z",
     "shell.execute_reply.started": "2025-03-15T01:08:22.610364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1c1839400d463fbc1c7d64045d73a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deeb208839c41528bf5f93b9498d1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b91556484d4920a53dd8cbe40207d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b351eacab17b4653b469c5403f8cd315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90e090eb2444e4b5c18f4001752071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8b93a31fb84b05ad23e26a205b9d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bbbb051ca341af92afcfc9d094bc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de012741f14477c93dca726de14bae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (position_embedding): Embedding(257, 1024)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=1024, out_features=768, bias=False)\n",
       "  (text_projection): Linear(in_features=768, out_features=768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:04.394417Z",
     "iopub.status.busy": "2025-03-15T01:09:04.394117Z",
     "iopub.status.idle": "2025-03-15T01:09:04.595790Z",
     "shell.execute_reply": "2025-03-15T01:09:04.594810Z",
     "shell.execute_reply.started": "2025-03-15T01:09:04.394393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 171MB/s]\n"
     ]
    }
   ],
   "source": [
    "student_model = mobilenet_v3_small(pretrained=True)\n",
    "student_model.classifier[3]=nn.Linear(student_model.classifier[3].in_features,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:05.724798Z",
     "iopub.status.busy": "2025-03-15T01:09:05.724457Z",
     "iopub.status.idle": "2025-03-15T01:09:06.593596Z",
     "shell.execute_reply": "2025-03-15T01:09:06.592446Z",
     "shell.execute_reply.started": "2025-03-15T01:09:05.724767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda'  if torch.cuda.is_available() else \"cpu\")\n",
    "teacher_model.eval().to(device)\n",
    "student_model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:08.830009Z",
     "iopub.status.busy": "2025-03-15T01:09:08.829547Z",
     "iopub.status.idle": "2025-03-15T01:09:08.835817Z",
     "shell.execute_reply": "2025-03-15T01:09:08.834882Z",
     "shell.execute_reply.started": "2025-03-15T01:09:08.829969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466,0.4578275,0.40821073],std=[0.26862954,0.26130258,0.275777111])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:12.215043Z",
     "iopub.status.busy": "2025-03-15T01:09:12.214697Z",
     "iopub.status.idle": "2025-03-15T01:09:12.220368Z",
     "shell.execute_reply": "2025-03-15T01:09:12.219605Z",
     "shell.execute_reply.started": "2025-03-15T01:09:12.215013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,root_dir,transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir=root_dir\n",
    "        self.transform=transform\n",
    "        self.image_paths=[os.path.join(root_dir,f_name) for f_name in os.listdir(root_dir) if f_name.endswith(('.jpg','.jpeg','.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_path=self.image_paths[idx]\n",
    "        image=Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image_tensor=self.transform(image)\n",
    "        else:\n",
    "            image_tensor=transforms.ToTensor()(image)\n",
    "        return image_tensor,image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:16.145447Z",
     "iopub.status.busy": "2025-03-15T01:09:16.145164Z",
     "iopub.status.idle": "2025-03-15T01:09:16.149517Z",
     "shell.execute_reply": "2025-03-15T01:09:16.148728Z",
     "shell.execute_reply.started": "2025-03-15T01:09:16.145426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    image_tensors=[item[0] for item in batch]\n",
    "    pil_images=[item[1] for item in batch]\n",
    "    image_tensors=torch.stack(image_tensors)\n",
    "    return  image_tensors,pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:17.878000Z",
     "iopub.status.busy": "2025-03-15T01:09:17.877650Z",
     "iopub.status.idle": "2025-03-15T01:09:19.574480Z",
     "shell.execute_reply": "2025-03-15T01:09:19.573539Z",
     "shell.execute_reply.started": "2025-03-15T01:09:17.877970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset=CustomDataset(root_dir='/kaggle/input/coco-train-dataset/train2014',transform=transform)\n",
    "dataloader=DataLoader(dataset,batch_size=128,shuffle=True,num_workers=4,collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:55.882779Z",
     "iopub.status.busy": "2025-03-14T13:09:55.882430Z",
     "iopub.status.idle": "2025-03-14T13:09:55.887679Z",
     "shell.execute_reply": "2025-03-14T13:09:55.886900Z",
     "shell.execute_reply.started": "2025-03-14T13:09:55.882751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.Adam(student_model.parameters(), lr=0.005)\n",
    "# scheduler=optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:10:08.494099Z",
     "iopub.status.busy": "2025-03-14T13:10:08.493801Z",
     "iopub.status.idle": "2025-03-14T17:20:33.529156Z",
     "shell.execute_reply": "2025-03-14T17:20:33.528164Z",
     "shell.execute_reply.started": "2025-03-14T13:10:08.494080Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 25, Loss: 0.3992\n",
      "Epoch 1, Batch 50, Loss: 0.2276\n",
      "Epoch 1, Batch 75, Loss: 0.2159\n",
      "Epoch 1, Batch 100, Loss: 0.2084\n",
      "Epoch 1, Batch 125, Loss: 0.2054\n",
      "Epoch 1, Batch 150, Loss: 0.1988\n",
      "Epoch 1, Batch 175, Loss: 0.1964\n",
      "Epoch 1, Batch 200, Loss: 0.1958\n",
      "Epoch 1, Batch 225, Loss: 0.1930\n",
      "Epoch 1, Batch 250, Loss: 0.1922\n",
      "Epoch 1, Batch 275, Loss: 0.1896\n",
      "Epoch 1, Batch 300, Loss: 0.1865\n",
      "Epoch 1, Batch 325, Loss: 0.1857\n",
      "Epoch 1, Batch 350, Loss: 0.1832\n",
      "Epoch 1, Batch 375, Loss: 0.1835\n",
      "Epoch 1, Batch 400, Loss: 0.1848\n",
      "Epoch 1, Batch 425, Loss: 0.1821\n",
      "Epoch 1, Batch 450, Loss: 0.1805\n",
      "Epoch 1, Batch 475, Loss: 0.1818\n",
      "Epoch 1, Batch 500, Loss: 0.1803\n",
      "Epoch 1, Batch 525, Loss: 0.1779\n",
      "Epoch 1, Batch 550, Loss: 0.1783\n",
      "Epoch 1, Batch 575, Loss: 0.1761\n",
      "Epoch 1, Batch 600, Loss: 0.1776\n",
      "Epoch 1, Batch 625, Loss: 0.1770\n",
      "Epoch 1/5 completed\n",
      "Epoch 2, Batch 25, Loss: 0.1725\n",
      "Epoch 2, Batch 50, Loss: 0.1734\n",
      "Epoch 2, Batch 75, Loss: 0.1720\n",
      "Epoch 2, Batch 100, Loss: 0.1734\n",
      "Epoch 2, Batch 125, Loss: 0.1716\n",
      "Epoch 2, Batch 150, Loss: 0.1736\n",
      "Epoch 2, Batch 175, Loss: 0.1725\n",
      "Epoch 2, Batch 200, Loss: 0.1704\n",
      "Epoch 2, Batch 225, Loss: 0.1704\n",
      "Epoch 2, Batch 250, Loss: 0.1713\n",
      "Epoch 2, Batch 275, Loss: 0.1693\n",
      "Epoch 2, Batch 300, Loss: 0.1713\n",
      "Epoch 2, Batch 325, Loss: 0.1686\n",
      "Epoch 2, Batch 350, Loss: 0.1699\n",
      "Epoch 2, Batch 375, Loss: 0.1697\n",
      "Epoch 2, Batch 400, Loss: 0.1685\n",
      "Epoch 2, Batch 425, Loss: 0.1687\n",
      "Epoch 2, Batch 450, Loss: 0.1715\n",
      "Epoch 2, Batch 475, Loss: 0.1679\n",
      "Epoch 2, Batch 500, Loss: 0.1683\n",
      "Epoch 2, Batch 525, Loss: 0.1668\n",
      "Epoch 2, Batch 550, Loss: 0.1686\n",
      "Epoch 2, Batch 575, Loss: 0.1666\n",
      "Epoch 2, Batch 600, Loss: 0.1682\n",
      "Epoch 2, Batch 625, Loss: 0.1682\n",
      "Epoch 2/5 completed\n",
      "Epoch 3, Batch 25, Loss: 0.1630\n",
      "Epoch 3, Batch 50, Loss: 0.1620\n",
      "Epoch 3, Batch 75, Loss: 0.1631\n",
      "Epoch 3, Batch 100, Loss: 0.1618\n",
      "Epoch 3, Batch 125, Loss: 0.1608\n",
      "Epoch 3, Batch 150, Loss: 0.1622\n",
      "Epoch 3, Batch 175, Loss: 0.1597\n",
      "Epoch 3, Batch 200, Loss: 0.1622\n",
      "Epoch 3, Batch 225, Loss: 0.1606\n",
      "Epoch 3, Batch 250, Loss: 0.1601\n",
      "Epoch 3, Batch 275, Loss: 0.1614\n",
      "Epoch 3, Batch 300, Loss: 0.1608\n",
      "Epoch 3, Batch 325, Loss: 0.1618\n",
      "Epoch 3, Batch 350, Loss: 0.1603\n",
      "Epoch 3, Batch 375, Loss: 0.1620\n",
      "Epoch 3, Batch 400, Loss: 0.1626\n",
      "Epoch 3, Batch 425, Loss: 0.1595\n",
      "Epoch 3, Batch 450, Loss: 0.1605\n",
      "Epoch 3, Batch 475, Loss: 0.1609\n",
      "Epoch 3, Batch 500, Loss: 0.1602\n",
      "Epoch 3, Batch 525, Loss: 0.1609\n",
      "Epoch 3, Batch 550, Loss: 0.1610\n",
      "Epoch 3, Batch 575, Loss: 0.1607\n",
      "Epoch 3, Batch 600, Loss: 0.1611\n",
      "Epoch 3, Batch 625, Loss: 0.1615\n",
      "Epoch 3/5 completed\n",
      "Epoch 4, Batch 25, Loss: 0.1576\n",
      "Epoch 4, Batch 50, Loss: 0.1536\n",
      "Epoch 4, Batch 75, Loss: 0.1561\n",
      "Epoch 4, Batch 100, Loss: 0.1540\n",
      "Epoch 4, Batch 125, Loss: 0.1534\n",
      "Epoch 4, Batch 150, Loss: 0.1539\n",
      "Epoch 4, Batch 175, Loss: 0.1531\n",
      "Epoch 4, Batch 200, Loss: 0.1516\n",
      "Epoch 4, Batch 225, Loss: 0.1522\n",
      "Epoch 4, Batch 250, Loss: 0.1524\n",
      "Epoch 4, Batch 275, Loss: 0.1528\n",
      "Epoch 4, Batch 300, Loss: 0.1534\n",
      "Epoch 4, Batch 325, Loss: 0.1554\n",
      "Epoch 4, Batch 350, Loss: 0.1524\n",
      "Epoch 4, Batch 375, Loss: 0.1507\n",
      "Epoch 4, Batch 400, Loss: 0.1523\n",
      "Epoch 4, Batch 425, Loss: 0.1528\n",
      "Epoch 4, Batch 450, Loss: 0.1527\n",
      "Epoch 4, Batch 475, Loss: 0.1531\n",
      "Epoch 4, Batch 500, Loss: 0.1539\n",
      "Epoch 4, Batch 525, Loss: 0.1543\n",
      "Epoch 4, Batch 550, Loss: 0.1527\n",
      "Epoch 4, Batch 575, Loss: 0.1532\n",
      "Epoch 4, Batch 600, Loss: 0.1527\n",
      "Epoch 4, Batch 625, Loss: 0.1535\n",
      "Epoch 4/5 completed\n",
      "Epoch 5, Batch 25, Loss: 0.1484\n",
      "Epoch 5, Batch 50, Loss: 0.1471\n",
      "Epoch 5, Batch 75, Loss: 0.1475\n",
      "Epoch 5, Batch 100, Loss: 0.1466\n",
      "Epoch 5, Batch 125, Loss: 0.1469\n",
      "Epoch 5, Batch 150, Loss: 0.1462\n",
      "Epoch 5, Batch 175, Loss: 0.1461\n",
      "Epoch 5, Batch 200, Loss: 0.1468\n",
      "Epoch 5, Batch 225, Loss: 0.1463\n",
      "Epoch 5, Batch 250, Loss: 0.1449\n",
      "Epoch 5, Batch 275, Loss: 0.1469\n",
      "Epoch 5, Batch 300, Loss: 0.1468\n",
      "Epoch 5, Batch 325, Loss: 0.1459\n",
      "Epoch 5, Batch 350, Loss: 0.1470\n",
      "Epoch 5, Batch 375, Loss: 0.1470\n",
      "Epoch 5, Batch 400, Loss: 0.1468\n",
      "Epoch 5, Batch 425, Loss: 0.1459\n",
      "Epoch 5, Batch 450, Loss: 0.1467\n",
      "Epoch 5, Batch 475, Loss: 0.1457\n",
      "Epoch 5, Batch 500, Loss: 0.1468\n",
      "Epoch 5, Batch 525, Loss: 0.1466\n",
      "Epoch 5, Batch 550, Loss: 0.1457\n",
      "Epoch 5, Batch 575, Loss: 0.1469\n",
      "Epoch 5, Batch 600, Loss: 0.1466\n",
      "Epoch 5, Batch 625, Loss: 0.1463\n",
      "Epoch 5/5 completed\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    running_loss=0.0\n",
    "    for i,(images,images_pil) in enumerate(dataloader):\n",
    "        images=images.to(device)\n",
    "        with torch.no_grad():\n",
    "            pil_images=list(images_pil)\n",
    "            inputs=processor(images=pil_images,return_tensors='pt').to(device)\n",
    "            teacher_embeddings=teacher_model.get_image_features(**inputs)\n",
    "\n",
    "        student_embeddings=student_model(images)\n",
    "        loss=criterion(student_embeddings,teacher_embeddings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        if i%25==24:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/25:.4f}\")\n",
    "            running_loss=0.0\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T17:20:33.531116Z",
     "iopub.status.busy": "2025-03-14T17:20:33.530766Z",
     "iopub.status.idle": "2025-03-14T17:20:33.570796Z",
     "shell.execute_reply": "2025-03-14T17:20:33.569956Z",
     "shell.execute_reply.started": "2025-03-14T17:20:33.531084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), 'mobilenet_v3_small_distilled_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For 10 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:09:32.998462Z",
     "iopub.status.busy": "2025-03-15T01:09:32.998130Z",
     "iopub.status.idle": "2025-03-15T09:24:31.405384Z",
     "shell.execute_reply": "2025-03-15T09:24:31.404208Z",
     "shell.execute_reply.started": "2025-03-15T01:09:32.998431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 25, Loss: 0.3970\n",
      "Epoch 1, Batch 50, Loss: 0.2279\n",
      "Epoch 1, Batch 75, Loss: 0.2143\n",
      "Epoch 1, Batch 100, Loss: 0.2081\n",
      "Epoch 1, Batch 125, Loss: 0.2042\n",
      "Epoch 1, Batch 150, Loss: 0.2009\n",
      "Epoch 1, Batch 175, Loss: 0.1981\n",
      "Epoch 1, Batch 200, Loss: 0.1949\n",
      "Epoch 1, Batch 225, Loss: 0.1939\n",
      "Epoch 1, Batch 250, Loss: 0.1900\n",
      "Epoch 1, Batch 275, Loss: 0.1888\n",
      "Epoch 1, Batch 300, Loss: 0.1893\n",
      "Epoch 1, Batch 325, Loss: 0.1876\n",
      "Epoch 1, Batch 350, Loss: 0.1840\n",
      "Epoch 1, Batch 375, Loss: 0.1841\n",
      "Epoch 1, Batch 400, Loss: 0.1836\n",
      "Epoch 1, Batch 425, Loss: 0.1812\n",
      "Epoch 1, Batch 450, Loss: 0.1814\n",
      "Epoch 1, Batch 475, Loss: 0.1807\n",
      "Epoch 1, Batch 500, Loss: 0.1806\n",
      "Epoch 1, Batch 525, Loss: 0.1783\n",
      "Epoch 1, Batch 550, Loss: 0.1793\n",
      "Epoch 1, Batch 575, Loss: 0.1778\n",
      "Epoch 1, Batch 600, Loss: 0.1795\n",
      "Epoch 1, Batch 625, Loss: 0.1781\n",
      "Epoch 1/10 completed\n",
      "Epoch 2, Batch 25, Loss: 0.1749\n",
      "Epoch 2, Batch 50, Loss: 0.1733\n",
      "Epoch 2, Batch 75, Loss: 0.1729\n",
      "Epoch 2, Batch 100, Loss: 0.1726\n",
      "Epoch 2, Batch 125, Loss: 0.1739\n",
      "Epoch 2, Batch 150, Loss: 0.1722\n",
      "Epoch 2, Batch 175, Loss: 0.1736\n",
      "Epoch 2, Batch 200, Loss: 0.1720\n",
      "Epoch 2, Batch 225, Loss: 0.1732\n",
      "Epoch 2, Batch 250, Loss: 0.1719\n",
      "Epoch 2, Batch 275, Loss: 0.1713\n",
      "Epoch 2, Batch 300, Loss: 0.1713\n",
      "Epoch 2, Batch 325, Loss: 0.1724\n",
      "Epoch 2, Batch 350, Loss: 0.1724\n",
      "Epoch 2, Batch 375, Loss: 0.1695\n",
      "Epoch 2, Batch 400, Loss: 0.1715\n",
      "Epoch 2, Batch 425, Loss: 0.1700\n",
      "Epoch 2, Batch 450, Loss: 0.1695\n",
      "Epoch 2, Batch 475, Loss: 0.1708\n",
      "Epoch 2, Batch 500, Loss: 0.1694\n",
      "Epoch 2, Batch 525, Loss: 0.1691\n",
      "Epoch 2, Batch 550, Loss: 0.1708\n",
      "Epoch 2, Batch 575, Loss: 0.1704\n",
      "Epoch 2, Batch 600, Loss: 0.1686\n",
      "Epoch 2, Batch 625, Loss: 0.1688\n",
      "Epoch 2/10 completed\n",
      "Epoch 3, Batch 25, Loss: 0.1655\n",
      "Epoch 3, Batch 50, Loss: 0.1661\n",
      "Epoch 3, Batch 75, Loss: 0.1657\n",
      "Epoch 3, Batch 100, Loss: 0.1640\n",
      "Epoch 3, Batch 125, Loss: 0.1667\n",
      "Epoch 3, Batch 150, Loss: 0.1645\n",
      "Epoch 3, Batch 175, Loss: 0.1645\n",
      "Epoch 3, Batch 200, Loss: 0.1640\n",
      "Epoch 3, Batch 225, Loss: 0.1648\n",
      "Epoch 3, Batch 250, Loss: 0.1653\n",
      "Epoch 3, Batch 275, Loss: 0.1637\n",
      "Epoch 3, Batch 300, Loss: 0.1660\n",
      "Epoch 3, Batch 325, Loss: 0.1661\n",
      "Epoch 3, Batch 350, Loss: 0.1648\n",
      "Epoch 3, Batch 375, Loss: 0.1644\n",
      "Epoch 3, Batch 400, Loss: 0.1642\n",
      "Epoch 3, Batch 425, Loss: 0.1646\n",
      "Epoch 3, Batch 450, Loss: 0.1633\n",
      "Epoch 3, Batch 475, Loss: 0.1643\n",
      "Epoch 3, Batch 500, Loss: 0.1648\n",
      "Epoch 3, Batch 525, Loss: 0.1639\n",
      "Epoch 3, Batch 550, Loss: 0.1637\n",
      "Epoch 3, Batch 575, Loss: 0.1637\n",
      "Epoch 3, Batch 600, Loss: 0.1623\n",
      "Epoch 3, Batch 625, Loss: 0.1617\n",
      "Epoch 3/10 completed\n",
      "Epoch 4, Batch 25, Loss: 0.1611\n",
      "Epoch 4, Batch 50, Loss: 0.1595\n",
      "Epoch 4, Batch 75, Loss: 0.1590\n",
      "Epoch 4, Batch 100, Loss: 0.1603\n",
      "Epoch 4, Batch 125, Loss: 0.1592\n",
      "Epoch 4, Batch 150, Loss: 0.1586\n",
      "Epoch 4, Batch 175, Loss: 0.1583\n",
      "Epoch 4, Batch 200, Loss: 0.1580\n",
      "Epoch 4, Batch 225, Loss: 0.1590\n",
      "Epoch 4, Batch 250, Loss: 0.1586\n",
      "Epoch 4, Batch 275, Loss: 0.1598\n",
      "Epoch 4, Batch 300, Loss: 0.1574\n",
      "Epoch 4, Batch 325, Loss: 0.1598\n",
      "Epoch 4, Batch 350, Loss: 0.1586\n",
      "Epoch 4, Batch 375, Loss: 0.1590\n",
      "Epoch 4, Batch 400, Loss: 0.1599\n",
      "Epoch 4, Batch 425, Loss: 0.1591\n",
      "Epoch 4, Batch 450, Loss: 0.1585\n",
      "Epoch 4, Batch 475, Loss: 0.1583\n",
      "Epoch 4, Batch 500, Loss: 0.1597\n",
      "Epoch 4, Batch 525, Loss: 0.1598\n",
      "Epoch 4, Batch 550, Loss: 0.1601\n",
      "Epoch 4, Batch 575, Loss: 0.1584\n",
      "Epoch 4, Batch 600, Loss: 0.1574\n",
      "Epoch 4, Batch 625, Loss: 0.1587\n",
      "Epoch 4/10 completed\n",
      "Epoch 5, Batch 25, Loss: 0.1540\n",
      "Epoch 5, Batch 50, Loss: 0.1532\n",
      "Epoch 5, Batch 75, Loss: 0.1547\n",
      "Epoch 5, Batch 100, Loss: 0.1539\n",
      "Epoch 5, Batch 125, Loss: 0.1527\n",
      "Epoch 5, Batch 150, Loss: 0.1548\n",
      "Epoch 5, Batch 175, Loss: 0.1549\n",
      "Epoch 5, Batch 200, Loss: 0.1542\n",
      "Epoch 5, Batch 225, Loss: 0.1550\n",
      "Epoch 5, Batch 250, Loss: 0.1541\n",
      "Epoch 5, Batch 275, Loss: 0.1550\n",
      "Epoch 5, Batch 300, Loss: 0.1539\n",
      "Epoch 5, Batch 325, Loss: 0.1547\n",
      "Epoch 5, Batch 350, Loss: 0.1555\n",
      "Epoch 5, Batch 375, Loss: 0.1539\n",
      "Epoch 5, Batch 400, Loss: 0.1537\n",
      "Epoch 5, Batch 425, Loss: 0.1547\n",
      "Epoch 5, Batch 450, Loss: 0.1551\n",
      "Epoch 5, Batch 475, Loss: 0.1539\n",
      "Epoch 5, Batch 500, Loss: 0.1548\n",
      "Epoch 5, Batch 525, Loss: 0.1563\n",
      "Epoch 5, Batch 550, Loss: 0.1570\n",
      "Epoch 5, Batch 575, Loss: 0.1548\n",
      "Epoch 5, Batch 600, Loss: 0.1548\n",
      "Epoch 5, Batch 625, Loss: 0.1524\n",
      "Epoch 5/10 completed\n",
      "Epoch 6, Batch 25, Loss: 0.1507\n",
      "Epoch 6, Batch 50, Loss: 0.1489\n",
      "Epoch 6, Batch 75, Loss: 0.1485\n",
      "Epoch 6, Batch 100, Loss: 0.1490\n",
      "Epoch 6, Batch 125, Loss: 0.1498\n",
      "Epoch 6, Batch 150, Loss: 0.1493\n",
      "Epoch 6, Batch 175, Loss: 0.1475\n",
      "Epoch 6, Batch 200, Loss: 0.1495\n",
      "Epoch 6, Batch 225, Loss: 0.1502\n",
      "Epoch 6, Batch 250, Loss: 0.1492\n",
      "Epoch 6, Batch 275, Loss: 0.1492\n",
      "Epoch 6, Batch 300, Loss: 0.1499\n",
      "Epoch 6, Batch 325, Loss: 0.1494\n",
      "Epoch 6, Batch 350, Loss: 0.1511\n",
      "Epoch 6, Batch 375, Loss: 0.1495\n",
      "Epoch 6, Batch 400, Loss: 0.1493\n",
      "Epoch 6, Batch 425, Loss: 0.1495\n",
      "Epoch 6, Batch 450, Loss: 0.1509\n",
      "Epoch 6, Batch 475, Loss: 0.1491\n",
      "Epoch 6, Batch 500, Loss: 0.1506\n",
      "Epoch 6, Batch 525, Loss: 0.1492\n",
      "Epoch 6, Batch 550, Loss: 0.1494\n",
      "Epoch 6, Batch 575, Loss: 0.1516\n",
      "Epoch 6, Batch 600, Loss: 0.1499\n",
      "Epoch 6, Batch 625, Loss: 0.1499\n",
      "Epoch 6/10 completed\n",
      "Epoch 7, Batch 25, Loss: 0.1465\n",
      "Epoch 7, Batch 50, Loss: 0.1449\n",
      "Epoch 7, Batch 75, Loss: 0.1458\n",
      "Epoch 7, Batch 100, Loss: 0.1449\n",
      "Epoch 7, Batch 125, Loss: 0.1441\n",
      "Epoch 7, Batch 150, Loss: 0.1440\n",
      "Epoch 7, Batch 175, Loss: 0.1441\n",
      "Epoch 7, Batch 200, Loss: 0.1446\n",
      "Epoch 7, Batch 225, Loss: 0.1457\n",
      "Epoch 7, Batch 250, Loss: 0.1436\n",
      "Epoch 7, Batch 275, Loss: 0.1440\n",
      "Epoch 7, Batch 300, Loss: 0.1454\n",
      "Epoch 7, Batch 325, Loss: 0.1431\n",
      "Epoch 7, Batch 350, Loss: 0.1456\n",
      "Epoch 7, Batch 375, Loss: 0.1447\n",
      "Epoch 7, Batch 400, Loss: 0.1443\n",
      "Epoch 7, Batch 425, Loss: 0.1471\n",
      "Epoch 7, Batch 450, Loss: 0.1442\n",
      "Epoch 7, Batch 475, Loss: 0.1447\n",
      "Epoch 7, Batch 500, Loss: 0.1456\n",
      "Epoch 7, Batch 525, Loss: 0.1453\n",
      "Epoch 7, Batch 550, Loss: 0.1445\n",
      "Epoch 7, Batch 575, Loss: 0.1458\n",
      "Epoch 7, Batch 600, Loss: 0.1459\n",
      "Epoch 7, Batch 625, Loss: 0.1458\n",
      "Epoch 7/10 completed\n",
      "Epoch 8, Batch 25, Loss: 0.1419\n",
      "Epoch 8, Batch 50, Loss: 0.1411\n",
      "Epoch 8, Batch 75, Loss: 0.1398\n",
      "Epoch 8, Batch 100, Loss: 0.1403\n",
      "Epoch 8, Batch 125, Loss: 0.1391\n",
      "Epoch 8, Batch 150, Loss: 0.1406\n",
      "Epoch 8, Batch 175, Loss: 0.1405\n",
      "Epoch 8, Batch 200, Loss: 0.1422\n",
      "Epoch 8, Batch 225, Loss: 0.1404\n",
      "Epoch 8, Batch 250, Loss: 0.1396\n",
      "Epoch 8, Batch 275, Loss: 0.1410\n",
      "Epoch 8, Batch 300, Loss: 0.1402\n",
      "Epoch 8, Batch 325, Loss: 0.1394\n",
      "Epoch 8, Batch 350, Loss: 0.1406\n",
      "Epoch 8, Batch 375, Loss: 0.1399\n",
      "Epoch 8, Batch 400, Loss: 0.1409\n",
      "Epoch 8, Batch 425, Loss: 0.1404\n",
      "Epoch 8, Batch 450, Loss: 0.1418\n",
      "Epoch 8, Batch 475, Loss: 0.1396\n",
      "Epoch 8, Batch 500, Loss: 0.1402\n",
      "Epoch 8, Batch 525, Loss: 0.1407\n",
      "Epoch 8, Batch 550, Loss: 0.1399\n",
      "Epoch 8, Batch 575, Loss: 0.1400\n",
      "Epoch 8, Batch 600, Loss: 0.1389\n",
      "Epoch 8, Batch 625, Loss: 0.1425\n",
      "Epoch 8/10 completed\n",
      "Epoch 9, Batch 25, Loss: 0.1368\n",
      "Epoch 9, Batch 50, Loss: 0.1363\n",
      "Epoch 9, Batch 75, Loss: 0.1358\n",
      "Epoch 9, Batch 100, Loss: 0.1382\n",
      "Epoch 9, Batch 125, Loss: 0.1366\n",
      "Epoch 9, Batch 150, Loss: 0.1373\n",
      "Epoch 9, Batch 175, Loss: 0.1363\n",
      "Epoch 9, Batch 200, Loss: 0.1348\n",
      "Epoch 9, Batch 225, Loss: 0.1366\n",
      "Epoch 9, Batch 250, Loss: 0.1371\n",
      "Epoch 9, Batch 275, Loss: 0.1369\n",
      "Epoch 9, Batch 300, Loss: 0.1380\n",
      "Epoch 9, Batch 325, Loss: 0.1369\n",
      "Epoch 9, Batch 350, Loss: 0.1365\n",
      "Epoch 9, Batch 375, Loss: 0.1369\n",
      "Epoch 9, Batch 400, Loss: 0.1366\n",
      "Epoch 9, Batch 425, Loss: 0.1366\n",
      "Epoch 9, Batch 450, Loss: 0.1382\n",
      "Epoch 9, Batch 475, Loss: 0.1369\n",
      "Epoch 9, Batch 500, Loss: 0.1367\n",
      "Epoch 9, Batch 525, Loss: 0.1361\n",
      "Epoch 9, Batch 550, Loss: 0.1371\n",
      "Epoch 9, Batch 575, Loss: 0.1347\n",
      "Epoch 9, Batch 600, Loss: 0.1378\n",
      "Epoch 9, Batch 625, Loss: 0.1368\n",
      "Epoch 9/10 completed\n",
      "Epoch 10, Batch 25, Loss: 0.1350\n",
      "Epoch 10, Batch 50, Loss: 0.1339\n",
      "Epoch 10, Batch 75, Loss: 0.1350\n",
      "Epoch 10, Batch 100, Loss: 0.1339\n",
      "Epoch 10, Batch 125, Loss: 0.1347\n",
      "Epoch 10, Batch 150, Loss: 0.1340\n",
      "Epoch 10, Batch 175, Loss: 0.1342\n",
      "Epoch 10, Batch 200, Loss: 0.1335\n",
      "Epoch 10, Batch 225, Loss: 0.1351\n",
      "Epoch 10, Batch 250, Loss: 0.1331\n",
      "Epoch 10, Batch 275, Loss: 0.1330\n",
      "Epoch 10, Batch 300, Loss: 0.1337\n",
      "Epoch 10, Batch 325, Loss: 0.1340\n",
      "Epoch 10, Batch 350, Loss: 0.1320\n",
      "Epoch 10, Batch 375, Loss: 0.1345\n",
      "Epoch 10, Batch 400, Loss: 0.1348\n",
      "Epoch 10, Batch 425, Loss: 0.1347\n",
      "Epoch 10, Batch 450, Loss: 0.1347\n",
      "Epoch 10, Batch 475, Loss: 0.1345\n",
      "Epoch 10, Batch 500, Loss: 0.1338\n",
      "Epoch 10, Batch 525, Loss: 0.1332\n",
      "Epoch 10, Batch 550, Loss: 0.1349\n",
      "Epoch 10, Batch 575, Loss: 0.1342\n",
      "Epoch 10, Batch 600, Loss: 0.1360\n",
      "Epoch 10, Batch 625, Loss: 0.1349\n",
      "Epoch 10/10 completed\n"
     ]
    }
   ],
   "source": [
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.Adam(student_model.parameters(), lr=0.005)\n",
    "scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\n",
    "\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    running_loss=0.0\n",
    "    for i,(images,images_pil) in enumerate(dataloader):\n",
    "        images=images.to(device)\n",
    "        with torch.no_grad():\n",
    "            pil_images=list(images_pil)\n",
    "            inputs=processor(images=pil_images,return_tensors='pt').to(device)\n",
    "            teacher_embeddings=teacher_model.get_image_features(**inputs)\n",
    "\n",
    "        student_embeddings=student_model(images)\n",
    "        loss=criterion(student_embeddings,teacher_embeddings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        if i%25==24:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/25:.4f}\")\n",
    "            running_loss=0.0\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:24:31.407235Z",
     "iopub.status.busy": "2025-03-15T09:24:31.406946Z",
     "iopub.status.idle": "2025-03-15T09:24:31.447280Z",
     "shell.execute_reply": "2025-03-15T09:24:31.446396Z",
     "shell.execute_reply.started": "2025-03-15T09:24:31.407207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), 'mobilenet_v3_small_distilled_new_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:25:46.617533Z",
     "iopub.status.busy": "2025-03-15T09:25:46.617238Z",
     "iopub.status.idle": "2025-03-15T09:25:46.728579Z",
     "shell.execute_reply": "2025-03-15T09:25:46.727657Z",
     "shell.execute_reply.started": "2025-03-15T09:25:46.617512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "student_model.eval()\n",
    "image=Image.open('/kaggle/input/coco-train-dataset/train2014/COCO_train2014_000000000009.jpg').convert('RGB')\n",
    "input_tensor=processor(images=image,return_tensors='pt').to(device)\n",
    "input_tensor=input_tensor['pixel_values']\n",
    "with torch.no_grad():\n",
    "    teacher_embedding=teacher_model.get_image_features(input_tensor)\n",
    "with torch.no_grad():\n",
    "    student_embedding=student_model(input_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:25:47.769100Z",
     "iopub.status.busy": "2025-03-15T09:25:47.768670Z",
     "iopub.status.idle": "2025-03-15T09:25:47.810619Z",
     "shell.execute_reply": "2025-03-15T09:25:47.809746Z",
     "shell.execute_reply.started": "2025-03-15T09:25:47.769064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher embedding shape: torch.Size([1, 768])\n",
      "Student embedding shape: torch.Size([1, 768])\n",
      "Teacher L2 norm: 19.493438720703125\n",
      "Student L2 norm: 16.585071563720703\n"
     ]
    }
   ],
   "source": [
    "print(\"Teacher embedding shape:\", teacher_embedding.shape)\n",
    "print(\"Student embedding shape:\", student_embedding.shape)\n",
    "\n",
    "teacher_norm = torch.norm(teacher_embedding, p=2, dim=1)\n",
    "student_norm = torch.norm(student_embedding, p=2, dim=1)\n",
    "\n",
    "print(\"Teacher L2 norm:\", teacher_norm.item())\n",
    "print(\"Student L2 norm:\", student_norm.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:25:52.998631Z",
     "iopub.status.busy": "2025-03-15T09:25:52.998346Z",
     "iopub.status.idle": "2025-03-15T09:25:53.051349Z",
     "shell.execute_reply": "2025-03-15T09:25:53.050637Z",
     "shell.execute_reply.started": "2025-03-15T09:25:52.998610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher normalized norm: 1.0\n",
      "Student normalized norm: 0.9999999403953552\n",
      "Normalized MSE: 0.00020227096683811396\n",
      "Cosine Similarity: 0.9223280549049377\n"
     ]
    }
   ],
   "source": [
    "teacher_embedding# Assuming your code from earlier\n",
    "with torch.no_grad():\n",
    "    teacher_embedding = teacher_model.get_image_features(input_tensor)  # or encode_image\n",
    "    student_embedding = student_model(input_tensor)\n",
    "\n",
    "# Normalize\n",
    "teacher_normalized = nn.functional.normalize(teacher_embedding, p=2, dim=1)\n",
    "student_normalized = nn.functional.normalize(student_embedding, p=2, dim=1)\n",
    "\n",
    "# Check norms (should be 1)\n",
    "print(\"Teacher normalized norm:\", torch.norm(teacher_normalized, p=2, dim=1).item())\n",
    "print(\"Student normalized norm:\", torch.norm(student_normalized, p=2, dim=1).item())\n",
    "\n",
    "# Compute normalized MSE and cosine similarity\n",
    "mse_normalized = nn.MSELoss()(student_normalized, teacher_normalized)\n",
    "cos_sim = nn.functional.cosine_similarity(student_normalized, teacher_normalized).mean()\n",
    "\n",
    "print(\"Normalized MSE:\", mse_normalized.item())\n",
    "print(\"Cosine Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:26:10.999563Z",
     "iopub.status.busy": "2025-03-15T09:26:10.999268Z",
     "iopub.status.idle": "2025-03-15T09:26:11.051722Z",
     "shell.execute_reply": "2025-03-15T09:26:11.051032Z",
     "shell.execute_reply.started": "2025-03-15T09:26:10.999542Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher normalized norm: 1.0\n",
      "Student normalized norm: 0.9999999403953552\n",
      "Normalized MSE: 0.00020227096683811396\n",
      "Cosine Similarity: 0.9223280549049377\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    teacher_embedding = teacher_model.get_image_features(input_tensor)  # or encode_image\n",
    "    student_embedding = student_model(input_tensor)\n",
    "\n",
    "# Normalize\n",
    "teacher_normalized = nn.functional.normalize(teacher_embedding, p=2, dim=1)\n",
    "student_normalized = nn.functional.normalize(student_embedding, p=2, dim=1)\n",
    "\n",
    "# Compute metrics\n",
    "mse_normalized = nn.MSELoss()(teacher_normalized, student_normalized)\n",
    "cos_sim = nn.functional.cosine_similarity(teacher_normalized, student_normalized).mean()\n",
    "\n",
    "print(\"Teacher normalized norm:\", torch.norm(teacher_normalized, p=2, dim=1).item())\n",
    "print(\"Student normalized norm:\", torch.norm(student_normalized, p=2, dim=1).item())\n",
    "print(\"Normalized MSE:\", mse_normalized.item())\n",
    "print(\"Cosine Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T09:26:24.837881Z",
     "iopub.status.busy": "2025-03-15T09:26:24.837519Z",
     "iopub.status.idle": "2025-03-15T09:26:24.852424Z",
     "shell.execute_reply": "2025-03-15T09:26:24.851740Z",
     "shell.execute_reply.started": "2025-03-15T09:26:24.837825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute difference: 0.011231629177927971\n"
     ]
    }
   ],
   "source": [
    "diff = (teacher_normalized - student_normalized).abs().mean()\n",
    "print(\"Mean absolute difference:\", diff.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6867734,
     "sourceId": 11027944,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
